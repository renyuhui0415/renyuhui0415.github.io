<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="keywords" content="Hexo Theme Redefine"><meta name="author" content="StarHui"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://npm.elemecdn.com" crossorigin><link rel="canonical" href="https://renyuhui0415.github.io/post/linear_regression_experiment.html"><meta name="robots" content="index,follow"><meta name="googlebot" content="index,follow"><meta name="revisit-after" content="1 days"><meta name="description" content="线性回归实战"><meta property="og:type" content="article"><meta property="og:title" content="Linear Regression Experiment"><meta property="og:url" content="https://renyuhui0415.github.io/post/Linear_Regression_Experiment.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="线性回归实战"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/igt6yNA1.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/jXwHOVPr.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/be3QgMNY.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/3VoYNJbK.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/mwXMHMUq.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/elkjcAP4.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/g8z5yIRg.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/tcejuY9f.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/xo2LHa1d.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/vWibC7sJ.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/wWMZr4u2.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/nQP80IYK.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/ZR9dwMJH.png"><meta property="og:image" content="https://img1.imgtp.com/2023/06/25/ml5t6HZL.png"><meta property="article:published_time" content="2023-06-21T13:01:17.000Z"><meta property="article:modified_time" content="2023-06-26T13:33:32.473Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="AI"><meta property="article:tag" content="Linear Regression"><meta property="article:tag" content="Experiment"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://img1.imgtp.com/2023/06/25/igt6yNA1.png"><link rel="icon" type="image/png" href="https://img1.imgtp.com/2023/07/25/tDTWRQkr.png" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="https://img1.imgtp.com/2023/07/25/tDTWRQkr.png"><meta name="theme-color" content="#A31F34"><link rel="shortcut icon" href="https://img1.imgtp.com/2023/07/25/tDTWRQkr.png"><title>Linear Regression Experiment - StarHui Blog</title><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fonts/fonts.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fonts/Satoshi/satoshi.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fonts/Chillax/chillax.css"><script id="hexo-configurations">let Global=window.Global||{};Global.hexo_config={hostname:"renyuhui0415.github.io",root:"/",language:"en",path:"search.xml"},Global.theme_config={articles:{style:{font_size:"16px",line_height:1.5,image_border_radius:"14px",image_alignment:"center",image_caption:!1,link_icon:!0},word_count:{enable:!0,count:!0,min2read:!0},author_label:{enable:!0,auto:!1,list:[]},code_block:{copy:!0,style:"mac",font:{enable:!1,family:null,url:null}},toc:{enable:!0,max_depth:3,number:!1,expand:!0,init_open:!0},copyright:!0,lazyload:!0,recommendation:{enable:!1,title:"推荐阅读",limit:3,mobile_limit:2,placeholder:"/images/wallhaven-wqery6-light.webp",skip_dirs:[]}},colors:{primary:"#A31F34",secondary:null},global:{fonts:{chinese:{enable:!1,family:null,url:null},english:{enable:!1,family:null,url:null}},content_max_width:"1000px",sidebar_width:"210px",hover:{shadow:!1,scale:!0},scroll_progress:{bar:!1,percentage:!0},busuanzi_counter:{enable:!0,site_pv:!0,site_uv:!0,post_pv:!0},pjax:!0,open_graph:!0,google_analytics:{enable:!1,id:null}},home_banner:{enable:!0,style:"fixed",image:{light:"https://img1.imgtp.com/2023/06/27/MFhdYvHL.png",dark:"https://img1.imgtp.com/2023/06/27/Sz5yAT7E.png"},title:"你好呀，欢迎来到我的博客！",subtitle:{text:["Hi"],hitokoto:{enable:!0,api:"https://v1.hitokoto.cn"},typing_speed:100,backing_speed:80,starting_delay:500,backing_delay:1500,loop:!0,smart_backspace:!0},text_color:{light:"#fff",dark:"#d1d1b6"},text_style:{title_size:"2.8rem",subtitle_size:"1.5rem",line_height:1.2},custom_font:{enable:!1,family:null,url:null},social_links:{enable:!0,links:{github:"https://github.com/renyuhui0415",instagram:null,zhihu:"https://www.zhihu.com/people/pretend-52-7",twitter:null,email:"renyuhui1864@foxmail.com"}}},plugins:{feed:{enable:!1},aplayer:{enable:!0,type:"fixed",audios:[{name:"无人之岛",artist:"任然",url:"https://game.renyuhui.top/static/audio/Unmanned_Island.mp3",cover:"https://img1.imgtp.com/2023/06/07/O3hqpU3p.png"}]},mermaid:{enable:!1,version:"9.3.0"}},version:"2.2.2",navbar:{auto_hide:!0,color:{left:"#f78736",right:"#367df7",transparency:35},links:{Home:{path:"/",icon:"fa-regular fa-house"},Projects:{icon:"fa-solid fa-link",submenus:{"My Game":"https://game.renyuhui.top/","My ChatGpt":"https://chat.renyuhui.top/"}},About:{icon:"fa-regular fa-user",submenus:{Me:"/about",Github:"https://github.com/renyuhui0415",Blog:"https://blog.csdn.net/weixin_73090892?type=blog",Friends:"/friends"}}},search:{enable:!0,preload:!0}},page_templates:{friends_column:2,tags_style:"blur"},home:{sidebar:{enable:!0,position:"right",first_item:"menu",announcement:"让自己发光，胜过埋怨一切黑暗。",links:{Archives:{path:"/archives",icon:"fa-regular fa-archive"},ShuoShuo:{path:"/essays",icon:"fa-regular fa-comment-dots icon-space"},Photo:{path:"/masonry",icon:"fa-solid fa-image"}}},article_date_format:"auto",categories:{enable:!0,limit:3},tags:{enable:!0,limit:3}},footerStart:"2023/6/6 13:37:00"},Global.language_ago={second:"%s seconds ago",minute:"%s minutes ago",hour:"%s hours ago",day:"%s days ago",week:"%s weeks ago",month:"%s months ago",year:"%s years ago"},Global.data_config={masonry:!0}</script><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fontawesome/fontawesome.min.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fontawesome/brands.min.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fontawesome/solid.min.css"><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/fontawesome/regular.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="progress-bar-container"><span class="pjax-progress-bar"></span> <span class="pjax-progress-icon"><i class="fa-solid fa-circle-notch fa-spin"></i></span></div><main class="page-container"><div class="main-content-container"><div class="main-content-header"><header class="navbar-container"><div class="navbar-content"><div class="left"><a class="logo-title" href="/">StarHui Blog</a></div><div class="right"><div class="desktop"><ul class="navbar-list"><li class="navbar-item"><a href="/"><i class="fa-regular fa-house"></i> HOME</a></li><li class="navbar-item"><a class="has-dropdown" href="#" onclick="return!1"><i class="fa-solid fa-link"></i> PROJECTS&nbsp;<i class="fa-solid fa-chevron-down"></i></a><ul class="sub-menu"><li><a target="_blank" rel="noopener" href="https://game.renyuhui.top/">MY GAME</a></li><li><a target="_blank" rel="noopener" href="https://chat.renyuhui.top/">MY CHATGPT</a></li></ul></li><li class="navbar-item"><a class="has-dropdown" href="#" onclick="return!1"><i class="fa-regular fa-user"></i> ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i></a><ul class="sub-menu"><li><a href="/about">ME</a></li><li><a target="_blank" rel="noopener" href="https://github.com/renyuhui0415">GITHUB</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_73090892?type=blog">BLOG</a></li><li><a href="/friends">FRIENDS</a></li></ul></li><li class="navbar-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div><div class="icon-item navbar-bar"><div class="navbar-bar-middle"></div></div></div></div></div><div class="navbar-drawer"><ul class="drawer-navbar-list"><li class="drawer-navbar-item flex-center"><a href="/"><i class="fa-regular fa-house"></i> HOME</a></li><li class="drawer-navbar-item flex-center"><a class="has-dropdown" href="#" onclick="return!1"><i class="fa-solid fa-link"></i> PROJECTS&nbsp;<i class="fa-solid fa-chevron-down"></i></a></li><li class="dropdown-item flex-center"><a class="dropdown-item" target="_blank" rel="noopener" href="https://game.renyuhui.top/">MY GAME</a></li><li class="dropdown-item flex-center"><a class="dropdown-item" target="_blank" rel="noopener" href="https://chat.renyuhui.top/">MY CHATGPT</a></li><li class="drawer-navbar-item flex-center"><a class="has-dropdown" href="#" onclick="return!1"><i class="fa-regular fa-user"></i> ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i></a></li><li class="dropdown-item flex-center"><a class="dropdown-item" href="/about">ME</a></li><li class="dropdown-item flex-center"><a class="dropdown-item" target="_blank" rel="noopener" href="https://github.com/renyuhui0415">GITHUB</a></li><li class="dropdown-item flex-center"><a class="dropdown-item" target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_73090892?type=blog">BLOG</a></li><li class="dropdown-item flex-center"><a class="dropdown-item" href="/friends">FRIENDS</a></li></ul></div><div class="window-mask"></div></header></div><div class="main-content-body"><div class="main-content"><div class="fade-in-down-animation"><div class="post-page-container"><div class="article-content-container"><div class="article-title"><img src="https://img1.imgtp.com/2023/06/25/k6cmzBz5.jpg" alt="Linear Regression Experiment"><h1 class="article-title-cover">Linear Regression Experiment</h1></div><div class="article-header"><div class="avatar"><img src="https://s1.ax1x.com/2023/06/06/pCPxj5d.jpg"></div><div class="info"><div class="author"><span class="name">StarHui</span> <span class="author-label">Lv2</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-pen-fancy"></i>&nbsp; <span class="desktop">2023-06-21 21:01:17</span> <span class="mobile">2023-06-21 21:01:17</span> <span class="hover-info">Created</span> </span><span class="article-date article-meta-item"><i class="fa-regular fa-wrench"></i>&nbsp; <span class="desktop">2023-06-26 21:33:32</span> <span class="mobile">2023-06-26 21:33:32</span> <span class="hover-info">Updated</span> </span><span class="article-categories article-meta-item"><i class="fa-regular fa-folders"></i>&nbsp;<ul><li><a href="/categories/Experiment/">Experiment</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fa-regular fa-tags"></i>&nbsp;<ul><li><a href="/tags/Deep-Learning/">Deep Learning</a>&nbsp;</li><li>| <a href="/tags/AI/">AI</a>&nbsp;</li><li>| <a href="/tags/Linear-Regression/">Linear Regression</a>&nbsp;</li><li>| <a href="/tags/Experiment/">Experiment</a>&nbsp;</li></ul></span><span class="article-wordcount article-meta-item"><i class="fa-regular fa-typewriter"></i>&nbsp;<span>1.5k Words</span> </span><span class="article-min2read article-meta-item"><i class="fa-regular fa-clock"></i>&nbsp;<span>6 Mins</span> </span><span class="article-pv article-meta-item"><i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content markdown-body"><h1 id="前言">前言</h1><p>学完之后，感觉有点不过瘾，所以在网上找了一个csv文件来试试线性回归<br><a class="link" target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/datasetdetail/5646/0">波士顿房价数据集 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br>先下载到本地后，接下来就开始吧。</p><h1 id="上传数据">上传数据</h1><p>由于我用的是colab，所以接下来就讲解colab如何导入cvs文件以及读取。</p><p><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/igt6yNA1.png"></p><p>点击上传文件，上传后找到该文件，右键复制路径</p><p><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/jXwHOVPr.png"></p><p>读取数据</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!pip install pandas</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'/housing.csv'</span>) <span class="comment"># ''里面的为复制的路径</span></span><br><span class="line">data</span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/be3QgMNY.png"><p></p><h1 id="数据预处理">数据预处理</h1><h2 id="数据清洗">数据清洗</h2><p>首先看一下有没有空值，可以使用isnull函数查看<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.isnull().<span class="built_in">sum</span>() <span class="comment">#sum函数累加统计</span></span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/3VoYNJbK.png"><p></p><p>以下是各字段的解释，图片来自网络截屏<br><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/mwXMHMUq.png"></p><p>接下来看看是否异常值，使用 describe函数</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.describe()</span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/elkjcAP4.png"><p></p><p>可以看出每一行的值都是正常的，没有异常值.<br>最后看一下有没有重复项。<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.duplicated() <span class="comment">#检查每一行是否重复性，没有返回false，有返回true</span></span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/g8z5yIRg.png"><p></p><h2 id="特征选择">特征选择</h2><p>由于参数太多，可能会影响后面模型的准确性，所以选择把不相关的特征删除。<br>就是删除相关系数小于0.5的特征，只保留大于等于0.5的特征。<br>首先计算每一个特征与标签的相关系数。<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">correlation_matrix = data.corr()  <span class="comment"># 计算相关系数矩阵</span></span><br><span class="line">correlation_with_label = correlation_matrix[<span class="string">'MEDV'</span>]  <span class="comment"># 提取目标变量(MEDV)与其他特征之间的相关系数</span></span><br><span class="line"></span><br><span class="line">sorted_correlation = correlation_with_label.<span class="built_in">abs</span>().sort_values(ascending=<span class="literal">False</span>)  <span class="comment"># 按相关系数绝对值降序排列</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sorted_correlation)</span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/tcejuY9f.png"><p></p><p>MEDV是本身，所以相关系数为1，我不知道怎么删除这个。除此之外，可以发现LSTAT、RM、PTRATIO 相关系数大于等于0.5了。<br>接下来画出这三个与标签的散点图<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制'LSTAT'与'MEDV'的散点图</span></span><br><span class="line">plt.scatter(data[<span class="string">'LSTAT'</span>], data[<span class="string">'MEDV'</span>])</span><br><span class="line">plt.xlabel(<span class="string">'LSTST'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'MEDV'</span>)</span><br><span class="line">plt.title(<span class="string">'Scatter plot: LSTST vs MEDV'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制'RM'与'MEDV'的散点图</span></span><br><span class="line">plt.scatter(data[<span class="string">'RM'</span>], data[<span class="string">'MEDV'</span>])</span><br><span class="line">plt.xlabel(<span class="string">'RM'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'MEDV'</span>)</span><br><span class="line">plt.title(<span class="string">'Scatter plot: RM vs MEDV'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制'PTRATIO'与'MEDV'的散点图</span></span><br><span class="line">plt.scatter(data[<span class="string">'PTRATIO'</span>], data[<span class="string">'MEDV'</span>])</span><br><span class="line">plt.xlabel(<span class="string">'PTRATIO'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'MEDV'</span>)</span><br><span class="line">plt.title(<span class="string">'Scatter plot: PTRATIO vs MEDV'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/xo2LHa1d.png"><p></p><p>此时的 data 是一个Pandas 数据帧（DataFrame）对象，可以使用type()函数看一下<br>此时由于里面有的是字符串型，这里就需要用到咱们之前讲过的数据预处理里面的 处理缺失值。让字符串那一列变成一个特征，这样就变成了0、1.<br>接下来把data切片转化为 features（矩阵）、lables（向量）<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">data_features = data.iloc[:, [<span class="number">12</span>, <span class="number">5</span>, <span class="number">10</span>]].values</span><br><span class="line">data_labels = data.iloc[:, <span class="number">13</span>].values</span><br><span class="line">features = torch.tensor(data_features, dtype=torch.float32)</span><br><span class="line">labels = torch.tensor(data_labels, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">features.shape, features, labels.shape, labels</span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/vWibC7sJ.png"><p></p><h2 id="特征放缩">特征放缩</h2><p>特征放缩是什么？为什么要进行特征放缩呢？先来看一张图</p><p><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/wWMZr4u2.png"></p><p>这三个是咱们的保留下来的特征，从图中咱们可以发现，这三个特征的平均值、最小值、最大值差的有点多。这样的差异会导致某些特征在模型训练中的权重更新过程中起主导作用，使得模型过于关注数值较大的特征，而忽略了其他特征的贡献。<br>通过特征放缩，可以将所有特征的数值调整到相似的尺度，减少数值差异对模型训练的影响，使得模型更加平衡地考虑不同特征的重要性。<br>而特征放缩有常用的有三个，标准化、Min-Max归一化方法、Min-Max归一化方法.<br><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/350656643">数据的特征放缩 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br>这里采用的是Min-Max归一化方法。<br>将原始值减去最小值，并将差值除以最大值与最小值之间的差，从而获得新的归一化值。</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">features = torch.tensor(scaler.fit_transform(features),dtype=torch.float32)</span><br><span class="line">labels = torch.tensor(scaler.fit_transform(labels.reshape(-<span class="number">1</span>, <span class="number">1</span>)),dtype=torch.float32)</span><br><span class="line">features,labels</span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/nQP80IYK.png"><p></p><p>可以发现、特征、标签都被归一化0~1之间了。</p><h1 id="读取数据集">读取数据集</h1><p>原理：创建下标索引数组，然后原地打乱。最后通过 for循环来选择 batch_size个下标（不一定，有可能 i + batch_size越界，然后取num_example ），最后通过这些下标来返回batch_size 个特征、标签<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size,features,labels</span>):</span><br><span class="line">  num_example = <span class="built_in">len</span>(features) <span class="comment">#特征数量</span></span><br><span class="line">  indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_example)) <span class="comment">#生成一个list，存储下标</span></span><br><span class="line">  random.shuffle(indices) <span class="comment">#把下标打乱</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">#开始批量返回batch_size个样本</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,num_example,batch_size):</span><br><span class="line">    batch_indices = torch.tensor(indices[i:<span class="built_in">min</span>(i + batch_size,num_example)]) <span class="comment">#选择样本下标</span></span><br><span class="line">    <span class="keyword">yield</span> features[batch_indices],labels[batch_indices]</span><br></pre></td></tr></table></figure></div>可以测试一下<br><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">    <span class="built_in">print</span>(X, <span class="string">'\n'</span>, y)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure></div><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/ZR9dwMJH.png"><p></p><h1 id="初始化模型参数">初始化模型参数</h1><p>还是w随机，b设置为0<br></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(<span class="number">3</span>,<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></div><p></p><h1 id="定义模型">定义模型</h1><p>由于这个是简单的线性回归, <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align:-.464ex" xmlns="http://www.w3.org/2000/svg" width="31.898ex" height="2.296ex" role="img" focusable="false" viewBox="0 -810 14099 1015"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(1823.6,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mn" transform="translate(749,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="msub" transform="translate(2976.1,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(4206.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5207.1,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mn" transform="translate(749,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="msub" transform="translate(6359.7,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(7368.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(8146.2,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(8590.9,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(9035.5,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(9480.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(10258.2,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="msub" transform="translate(11424.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(12669.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(13670,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g></g></g></svg></mjx-container></span>，所以和之前推导的公式一样，直接写即可。</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X, w, b</span>): </span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X, w) + b</span><br></pre></td></tr></table></figure></div><h1 id="定义损失函数">定义损失函数</h1><p>还是均分损失函数</p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):  </span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="number">2</span> / <span class="number">2</span> <span class="comment">#没有除以均值，在计算梯度的时候再除</span></span><br></pre></td></tr></table></figure></div># 定义优化算法<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params, lr, batch_size</span>):  <span class="comment">#params是所有参数w、b的列表；lr为学习率、baatch_size为样本数量</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad(): <span class="comment">#上下文，关闭梯度计算，确保在更新参数时不会计算梯度。</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">            param -= lr * param.grad / batch_size <span class="comment">#更新</span></span><br><span class="line">            param.grad.zero_() <span class="comment">#清空梯度，因为梯度默认累积</span></span><br></pre></td></tr></table></figure></div># 训练 最后就是训练了，和之前一样<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.03</span> <span class="comment"># 学习率</span></span><br><span class="line">num_epochs = <span class="number">3</span> <span class="comment">#迭代周期</span></span><br><span class="line"></span><br><span class="line">net = linreg </span><br><span class="line">loss = squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs): <span class="comment">#遍历迭代周期</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        l = loss(net(X, w, b), y) </span><br><span class="line">        l.<span class="built_in">sum</span>().backward()</span><br><span class="line">        sgd([w, b], lr, batch_size) </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        train_l = loss(net(features, w, b), labels)</span><br><span class="line">        score = mse_score(net(features, w, b), labels)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'epoch <span class="subst">{epoch + <span class="number">1</span>}</span>, loss <span class="subst">{<span class="built_in">float</span>(train_l.mean()):f}</span>, score <span class="subst">{<span class="built_in">float</span>(score):f}</span>'</span>)</span><br></pre></td></tr></table></figure></div><p></p><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mse_score</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_hat - y) ** <span class="number">2</span>).mean().sqrt()</span><br></pre></td></tr></table></figure></div><p><img lazyload="" src="/images/loading.svg" data-src="https://img1.imgtp.com/2023/06/25/ml5t6HZL.png"></p><h1 id="写在最后">写在最后</h1><p>其实这个和前面李沐老师讲的差不多，只不过多了一些数据处理操作。由于没有学过pandas，所以其中数据操作比较粗糙，敬请谅解！！！</p></div><div class="post-copyright-info"><div class="article-copyright-info-container"><ul><li><strong>Title:</strong> Linear Regression Experiment</li><li><strong>Author:</strong> StarHui</li><li><strong>Created at:</strong> 2023-06-21 21:01:17</li><li><strong>Updated at:</strong> 2023-06-26 21:33:32</li><li><strong>Link:</strong> https://renyuhui0415.github.io/post/Linear_Regression_Experiment.html</li><li><strong>License:</strong> This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.</li></ul></div></div><ul class="post-tags-box"><li class="tag-item"><a href="/tags/Deep-Learning/">#Deep Learning</a>&nbsp;</li><li class="tag-item"><a href="/tags/AI/">#AI</a>&nbsp;</li><li class="tag-item"><a href="/tags/Linear-Regression/">#Linear Regression</a>&nbsp;</li><li class="tag-item"><a href="/tags/Experiment/">#Experiment</a>&nbsp;</li></ul><div class="article-nav"><div class="article-prev"><a class="prev" rel="prev" href="/post/Softmax_Regression.html"><span class="left arrow-icon flex-center"><i class="fa-solid fa-chevron-left"></i> </span><span class="title flex-center"><span class="post-nav-title-item">Softmax Regression</span> <span class="post-nav-item">Prev posts</span></span></a></div><div class="article-next"><a class="next" rel="next" href="/post/Linear_Regression.html"><span class="title flex-center"><span class="post-nav-title-item">Linear Regression</span> <span class="post-nav-item">Next posts</span> </span><span class="right arrow-icon flex-center"><i class="fa-solid fa-chevron-right"></i></span></a></div></div><div class="comment-container"><div class="comments-container"><div id="comment-anchor"></div><div class="comment-area-title"><i class="fa-solid fa-comments"></i>&nbsp;Comments</div><div id="waline"></div><script type="module" data-pjax>import{init}from"https://evan.beee.top/js/waline.mjs";function loadWaline(){init({el:"#waline",serverURL:"https://comment.renyuhui.top/",lang:"zh-CN",dark:'body[class~="dark-mode"]',requiredMeta:["nick","mail"]})}{const e=setTimeout(()=>{loadWaline(),clearTimeout(e)},1e3)}</script></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><div class="toc-title">On this page</div><div class="page-title">Linear Regression Experiment</div><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%8A%E4%BC%A0%E6%95%B0%E6%8D%AE"><span class="nav-text">上传数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span class="nav-text">数据清洗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%94%BE%E7%BC%A9"><span class="nav-text">特征放缩</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">读取数据集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="nav-text">初始化模型参数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B"><span class="nav-text">定义模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">定义损失函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="nav-text">写在最后</span></a></li></ol></div></div></div></div></div></div></div><div class="main-content-footer"><footer class="footer"><div class="info-container"><div class="copyright-info">&copy; <span>2023</span> - 2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration:0.5s;color:#f54545"></i>&nbsp;&nbsp;<a href="/">StarHui</a></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div class="website-count info-item"><span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">VISITOR COUNT&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">TOTAL PAGE VIEWS&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span></span></div><div class="theme-info info-item"><span class="powered-by-container">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a></span><br><span class="theme-version-container">THEME&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.2.2</a></span></div><div>Blog up for <span class="odometer" id="runtime_days"></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec</div><script async data-pjax>try{function odometer_init(){document.querySelectorAll(".odometer").forEach(e=>{new Odometer({el:e,format:"( ddd).dd",duration:200})})}odometer_init()}catch(e){}</script></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="article-tools-list"><li class="right-bottom-tools page-aside-toggle"><i class="fa-regular fa-outdent"></i></li><li class="go-comment"><i class="fa-regular fa-comments"></i></li></ul></div></div><div class="right-side-tools-container"><div class="side-tools-container"><ul class="hidden-tools-list"><li class="right-bottom-tools tool-font-adjust-plus flex-center"><i class="fa-regular fa-magnifying-glass-plus"></i></li><li class="right-bottom-tools tool-font-adjust-minus flex-center"><i class="fa-regular fa-magnifying-glass-minus"></i></li><li class="right-bottom-tools tool-expand-width flex-center"><i class="fa-regular fa-expand"></i></li><li class="right-bottom-tools tool-dark-light-toggle flex-center"><i class="fa-regular fa-moon"></i></li><li class="right-bottom-tools tool-scroll-to-bottom flex-center"><i class="fa-regular fa-arrow-down"></i></li></ul><ul class="visible-tools-list"><li class="right-bottom-tools toggle-tools-list flex-center"><i class="fa-regular fa-cog fa-spin"></i></li><li class="right-bottom-tools tool-scroll-to-top flex-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="image-viewer-container"><img src=""></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fa-solid fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa-solid fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/utils.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/main.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/layouts/navbarShrink.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/tools/scrollTopBottom.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/tools/lightDarkSwitch.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/tools/localSearch.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/tools/codeBlock.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/layouts/lazyload.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/tools/runtime.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/libs/odometer.min.js"></script><link rel="stylesheet" href="//evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/assets/odometer-theme-minimal.css"><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/libs/Typed.min.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/plugins/typed.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/libs/minimasonry.min.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/plugins/masonry.js"></script><div class="post-scripts pjax"><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/tools/tocToggle.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/libs/anime.min.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/layouts/toc.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/plugins/tabs.js"></script></div><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/libs/pjax.min.js"></script><script>window.addEventListener("DOMContentLoaded",()=>{window.pjax=new Pjax({selectors:["head title",".page-container",".pjax"],history:!0,debug:!1,cacheBust:!1,timeout:0,analytics:!1,currentUrlFullReload:!1,scrollRestoration:!1}),document.addEventListener("pjax:send",()=>{Global.utils.pjaxProgressBarStart()}),document.addEventListener("pjax:complete",()=>{Global.utils.pjaxProgressBarEnd(),window.pjax.executeScripts(document.querySelectorAll("script[data-pjax], .pjax script")),Global.refresh()})})</script><div id="aplayer"></div><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/libs/APlayer.min.js"></script><script src="https://evan.beee.top/projects/hexo-theme-redefine@2.2.2/source/js/plugins/aplayer.js"></script></body></html>